# -*- coding: utf-8 -*-
"""Q2_Detect_CredCard_Anomal_GMM.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lpOIq9ZjjmVwtXHSb-FULEKRMMP26LMo
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import seaborn as sns

from subprocess import check_output
# print(check_output(["ls", "../input"]).decode("utf8"))

from google.colab import drive
drive.mount('/content/gdrive')
input_file = 'content/gdrive/My Drive/Colab Notebooks/creditcard.csv'

df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/creditcard.csv')
import matplotlib.gridspec as gridspec
features=['V12','V14', 'V16', 'V8', 'V20']
nplots=np.size(features)
plt.figure(figsize=(15,4*nplots))
gs = gridspec.GridSpec(nplots,1)
for i, feat in enumerate(features):
    ax = plt.subplot(gs[i])
    sns.distplot(df[feat][df.Class==1], bins=30)
    sns.distplot(df[feat][df.Class==0],bins=30)
    ax.legend(['fraudulent', 'non-fraudulent'],loc='best')
    ax.set_xlabel('')
    ax.set_title('Distribution of feature: ' + feat)

sns.pairplot(df[df.Class==1], vars=['V14', 'V16'], kind='reg', hue='Class')

df.columns

from sklearn.model_selection import train_test_split
from matplotlib.colors import LogNorm
from sklearn import mixture

df_0=df[df.Class==0]    #Dataset with non-fraudulent only
df_1=df[df.Class==1]    #Dataset with fraudulent only
df_0=df_0[['V14', 'V16','Class']]    #Select two most correlated features for now
df_1=df_1[['V14', 'V16', 'Class']]

#Split non-fraudulent data in 70% for training GMM and 30% for cross-validation and testing
X_train, X_test, y_train, y_test = train_test_split(df_0.drop(['Class'],axis=1), df_0['Class'] , test_size=0.3, random_state=0)
#Split the fraudulent data in 60% for cross-validation and 40% for testing
X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(df_1.drop(['Class'],axis=1), df_1['Class'] , test_size=0.4, random_state=0)


# Fit a Gaussian Mixture Model with the two components 'V14' and 'V16'
clf = mixture.GaussianMixture()
clf.fit(X_train)

# display predicted scores by the model as a contour plot
x = np.linspace(-18, 10)
y = np.linspace(-17, 9.)
X, Y = np.meshgrid(x, y)
XX = np.array([X.ravel(), Y.ravel()]).T
Z = -clf.score_samples(XX)
Z = Z.reshape(X.shape)
CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=1000.0), levels=np.logspace(0, 3, 10))
CB = plt.colorbar(CS, shrink=0.8, extend='both')
plt.scatter(X_train['V14'].values,X_train['V16'].values, 0.8)
plt.title('Negative log-likelihood traine using GMM')
plt.axis('tight')
plt.show()

from sklearn.metrics import average_precision_score
from sklearn.metrics import precision_recall_curve
y_test_proba = clf.score_samples(np.vstack([X_test, X_test_1]))
plt.plot(y_test_proba)
plt.title('Predicted probabilities for test dataset')

from sklearn.metrics import classification_report
from sklearn.metrics import average_precision_score
from sklearn.metrics import precision_recall_curve
T=-40
y_test_proba[y_test_proba>=T]=0
y_test_proba[y_test_proba<T]=1

y_test_orig=np.hstack([y_test, y_test_1])
print('Classification report for default n_components')
print(classification_report(y_test_orig, y_test_proba))

from sklearn.mixture import GaussianMixture

clf = mixture.GaussianMixture(n_components = 2, covariance_type='full',init_params='kmeans')
clf.fit(X_train)
y_test_proba = clf.score_samples(np.vstack([X_test, X_test_1]))

T=-40
y_test_proba[y_test_proba>=T]=0
y_test_proba[y_test_proba<T]=1

y_test_orig=np.hstack([y_test, y_test_1])
print('Classification report for n_components = 2')
print(classification_report(y_test_orig, y_test_proba))

clf = mixture.GaussianMixture(n_components = 3, covariance_type='full',init_params='kmeans')
clf.fit(X_train)
y_test_proba = clf.score_samples(np.vstack([X_test, X_test_1]))

T=-40
y_test_proba[y_test_proba>=T]=0
y_test_proba[y_test_proba<T]=1

y_test_orig=np.hstack([y_test, y_test_1])
print('Classification report for n_components = 3')
print(classification_report(y_test_orig, y_test_proba))

clf = mixture.GaussianMixture(n_components = 4, covariance_type='full',init_params='kmeans')
clf.fit(X_train)
y_test_proba = clf.score_samples(np.vstack([X_test, X_test_1]))

T=-40
y_test_proba[y_test_proba>=T]=0
y_test_proba[y_test_proba<T]=1

y_test_orig=np.hstack([y_test, y_test_1])
print('Classification report for n_components = 4')
print(classification_report(y_test_orig, y_test_proba))
print('Test AUCPR = ' + str(average_precision_score(y_test_orig, y_test_proba)))